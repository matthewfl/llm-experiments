{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c99595b-c139-4ec4-9dd2-a542d2491951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada5e23e0f3f4a0d96702770b98c1fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", device_map='auto') # load_in_4bit=True\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", device_map='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f3435bd-39c1-4830-9e46-35b33991b139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# # device = \"cuda\" # thmessages = [\n",
    "#     {\"role\": \"user\", \"content\": \"What is your favourite condiment?\"},\n",
    "#     {\"role\": \"assistant\", \"content\": \"Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!\"},\n",
    "#     {\"role\": \"user\", \"content\": \"Do you have mayonnaise recipes?\"}\n",
    "# ]\n",
    "\n",
    "# encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "\n",
    "# model_inputs = encodeds.to(model.device)messages = [\n",
    "#     {\"role\": \"user\", \"content\": \"What is your favourite condiment?\"},\n",
    "#     {\"role\": \"assistant\", \"content\": \"Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!\"},\n",
    "#     {\"role\": \"user\", \"content\": \"Do you have mayonnaise recipes?\"}\n",
    "# ]\n",
    "\n",
    "# encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "\n",
    "# # model_inputs = encodeds.to(model.device)e device to load the model onto\n",
    "# # device = 'cpu'\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", device_map='auto')\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", device_map='auto')\n",
    "\n",
    "\n",
    "# # model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4259ba14-87f5-4cfb-a09e-5572ab141c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is your favourite condiment?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Do you have mayonnaise recipes?\"}\n",
    "]\n",
    "\n",
    "encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "\n",
    "model_inputs = encodeds.to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20b33092-df72-4361-b202-ecf76be6dc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac5f0af3-9e0b-4cd5-aa2a-474d125844e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50e18ba9-be9a-4324-8d14-ec719ac6c31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "2024-03-03 23:35:57.219800: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-03 23:35:57.219863: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-03 23:35:57.550993: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-03 23:35:58.271223: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-03 23:36:02.139224: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12160661-8a42-48c8-a8e2-bda33fa3ee91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,   733, 16289, 28793,  1824,   349,   574, 16020,  2076,  2487,\n",
       "         28804,   733, 28748, 16289, 28793,  6824, 28725,   315, 28742, 28719,\n",
       "          3448, 10473,   298,   264,  1179, 11322, 19961,   302,  6138, 23598,\n",
       "         18342, 28723,   661, 13633,   776,   272,  1103,  3558,   302,   686,\n",
       "         16944, 15637,   423,   298,  5681,   315, 28742, 28719, 13198,   582,\n",
       "           297,   272,  6132, 28808,     2,   733, 16289, 28793,  2378,   368,\n",
       "           506,   993,  7136,   864, 21116, 28804,   733, 28748, 16289, 28793,\n",
       "         12875,  1970, 28808,  4003, 28742, 28713,   264,  3588,   304, 11495,\n",
       "           993,  7136,   864, 13405, 28723,   995, 28742,   584,   927, 28747,\n",
       "            13,    13, 28740, 28723, 28705, 28740,  9119,   337, 27227,    13,\n",
       "         28750, 28723, 28705, 28740,  9882, 20670,   302,   384,  1230,   266,\n",
       "          1580,   488,    13, 28770, 28723, 28705, 28740,  6211,   302,  5503,\n",
       "           325,  4230,  4362, 28725, 10035,   522, 28725,   442,  2061, 24403,\n",
       "          5503,  3791,  1489, 28731,    13, 28781, 28723, 28705, 28740,   298,\n",
       "         28705, 28750,  9882,  2345,  1053,   302,  3075,  8188, 21375,  4749,\n",
       "           442, 23598, 18342,    13, 28782, 28723, 21943,   298,  9230,    13,\n",
       "            13,  7489, 28725, 17470,   272,  9119,   337, 27227,   304,  1580,\n",
       "           488,   297,   264, 13494, 28725, 26898,   288,  2553,  1996,   590,\n",
       "         28742,   267,  1162,  9430, 28723,   330,  9550,   338,   302,  9685,\n",
       "           349,   264,  1179,  3028,   438,   456,  5430,   390,  1162, 28723,\n",
       "            13,    13,  6693, 28725,  1149,  8833,   272,  5503,  1215,  7160,\n",
       "         28725,   297,   264,  9026,  4454, 28725,  1312, 26898,   288, 10876,\n",
       "         28723,   851,   349,  1987,   877,  7550,  6219,   272, 16232,   304,\n",
       "           378, 28742, 28713,   767,  2870,   272,   993,  7136,   864,  6931,\n",
       "           304, 10558, 28724, 28723,  1047,   272, 16232,  8383,   298,   913,\n",
       "           737,   378,  1659,  7681,   442,  1191, 28715,   291, 28725,   368,\n",
       "           541,   967,   264,  1664, 17472,   302, 21375,  4749,   442,  2130,\n",
       "           298,  1316,   378,  1567,   852,  2553, 28723,    13,    13, 16114,\n",
       "           368, 28742,   333,  3886,   684,   264,  4008,   302,   272,  5503,\n",
       "           304,   272,   993,  7136,   864,   659,  6931,  2106, 28725,   368,\n",
       "           541,  1149,  8833,   272,  5503,   297,   264, 14889,  4454, 28723,\n",
       "         10339, 26898,   288,  1996,   544,   272,  5503,   349, 23799, 28723,\n",
       "            13,    13, 11491,   578, 28725,   967,   574, 11785,  3558,   302,\n",
       "         21375,  4749,   442, 23598, 18342,   304, 26898,   297,   264,  1628,\n",
       "           680,  9685,   298,  9230, 28723, 16881,   272, 13494,   395, 10409,\n",
       "         12551,   304, 23641,   380,   272,   993,  7136,   864,  1996,   368,\n",
       "         28742,   267,  4313,   298,   938,   378, 28723,    13,    13,  1608,\n",
       "          3258,   574, 28431,   770,   993,  7136,   864, 28808,   661, 28742,\n",
       "         28713,  1598,   356,  6830, 28727, 25809, 28725,   390,   264, 14217,\n",
       "         28725,   442,   390,   264,  2624,   354,   799, 10241,  1377, 28723,\n",
       "             2]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86b93a97-4ddd-4b6e-9b59-cf59cc1a6cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> [INST] What is your favourite condiment? [/INST]Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!</s> [INST] Do you have mayonnaise recipes? [/INST] Sure thing! Here's a simple and classic mayonnaise recipe. You'll need:\n",
      "\n",
      "1. 1 egg yolk\n",
      "2. 1 tablespoon of Dijon mustard\n",
      "3. 1 cup of oil (canola, vegetable, or light olive oil works best)\n",
      "4. 1 to 2 tablespoons of white wine vinegar or lemon juice\n",
      "5. Salt to taste\n",
      "\n",
      "First, combine the egg yolk and mustard in a bowl, whisking together until they're well mixed. A pinch of salt is a good idea at this stage as well.\n",
      "\n",
      "Next, start adding the oil very slowly, in a thin stream, while whisking constantly. This is called emulsifying the mixture and it's what makes the mayonnaise thick and creamy. If the mixture starts to look like it might separate or curdle, you can add a few drops of vinegar or water to help it come back together.\n",
      "\n",
      "Once you've added about a third of the oil and the mayonnaise has thickened, you can start adding the oil in a steady stream. Keep whisking until all the oil is incorporated.\n",
      "\n",
      "Finally, add your desired amount of vinegar or lemon juice and whisk in a little more salt to taste. Cover the bowl with plastic wrap and refrigerate the mayonnaise until you're ready to use it.\n",
      "\n",
      "Enjoy your homemade mayonnaise! It's great on sandwiches, as a dip, or as a base for other sauces.</s>\n"
     ]
    }
   ],
   "source": [
    "decoded = tokenizer.batch_decode(generated_ids.to('cpu'))\n",
    "print(decoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e581d703-09f8-4956-9542-04190cf1aca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
